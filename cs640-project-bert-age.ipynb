{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a715aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d949cb-67d5-4db1-9872-c3164280e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed499ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_dataset_1145.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be046f8e-e063-4be2-9d8c-aa42c5674dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].apply(lambda x:str(x).replace(\"nan\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f69bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>description</th>\n",
       "      <th>tweets</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>_____zac_____</td>\n",
       "      <td>zac ¢</td>\n",
       "      <td>en</td>\n",
       "      <td>_____Û___È_Ü´Ù</td>\n",
       "      <td>.The owner of drip doesnt even have 100 mill,...</td>\n",
       "      <td>labeled_users_1145/profile pics test/0.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>___aleia</td>\n",
       "      <td>_æ___ dad ___æ_</td>\n",
       "      <td>en</td>\n",
       "      <td>BLACK. LIVES. MATTER.</td>\n",
       "      <td>I haven’t talked to this girl since my sophomo...</td>\n",
       "      <td>labeled_users_1145/profile pics test/1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>___schaeffer___</td>\n",
       "      <td>Brenden Schaeffer</td>\n",
       "      <td>en</td>\n",
       "      <td>Culver-Stockton College '20 ¢ Ô_Ô_Ô KM 1548...</td>\n",
       "      <td>☝🏼👋🏼 ://t.co/7NcaO1fyc5 ://t.co/bkhrNcvp6Q  37...</td>\n",
       "      <td>labeled_users_1145/profile pics test/3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>__EmilyRice__</td>\n",
       "      <td>em</td>\n",
       "      <td>en</td>\n",
       "      <td>#TXST22</td>\n",
       "      <td>yes but come to san marcos and live with me 🥰...</td>\n",
       "      <td>labeled_users_1145/profile pics test/9.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>__ginaaaa__</td>\n",
       "      <td>Gina Marano</td>\n",
       "      <td>en</td>\n",
       "      <td>WVU Nursing ",
       "20</td>\n",
       "      <td>small :).Go get ready for dinner.   JACK are ...</td>\n",
       "      <td>labeled_users_1145/profile pics test/10.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0</td>\n",
       "      <td>Zgs_Apollo</td>\n",
       "      <td>Anthony Sharp</td>\n",
       "      <td>en</td>\n",
       "      <td>22 Youtuber &amp; Twitch Streamer trying to live t...</td>\n",
       "      <td>Goodnight my friends, much love.Drop a ❤️ if t...</td>\n",
       "      <td>labeled_users_1145/profile pics test/3266.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0</td>\n",
       "      <td>zmeadows_18</td>\n",
       "      <td>Z Meadows</td>\n",
       "      <td>und</td>\n",
       "      <td>|OUCÈ23__|</td>\n",
       "      <td>ROLL BOBBIES ROLL💚🖤💚🖤💚.We Are Texans! Im takin...</td>\n",
       "      <td>labeled_users_1145/profile pics test/3268.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0</td>\n",
       "      <td>ZoeCalamaco</td>\n",
       "      <td>Zoe _</td>\n",
       "      <td>no</td>\n",
       "      <td>Angelo state</td>\n",
       "      <td>one person followed me // automatically checke...</td>\n",
       "      <td>labeled_users_1145/profile pics test/3272.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>1</td>\n",
       "      <td>ZoPeachy</td>\n",
       "      <td>Zobella Thee Alpha __ê_____´Ù__ ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Harlot for hire. FinDom. 27. Nonbinary. they/t...</td>\n",
       "      <td>Good morning! Say it back ♡  Friday! Send to p...</td>\n",
       "      <td>labeled_users_1145/profile pics test/3274.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>0</td>\n",
       "      <td>zzzakari4</td>\n",
       "      <td>_«_«ê_«__«ê</td>\n",
       "      <td>en</td>\n",
       "      <td>i hate making bios oh my godddd UCIÈ21</td>\n",
       "      <td>i just know willows next album is gonna set me...</td>\n",
       "      <td>labeled_users_1145/profile pics test/3279.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1041 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age      screen_name                                               name  \\\n",
       "0       1    _____zac_____                                            zac ¢   \n",
       "1       0         ___aleia                              _æ___ dad ___æ_   \n",
       "2       0  ___schaeffer___                                  Brenden Schaeffer   \n",
       "3       0    __EmilyRice__                                                 em   \n",
       "4       0      __ginaaaa__                                        Gina Marano   \n",
       "...   ...              ...                                                ...   \n",
       "1036    0       Zgs_Apollo                                      Anthony Sharp   \n",
       "1037    0      zmeadows_18                                          Z Meadows   \n",
       "1038    0      ZoeCalamaco                                           Zoe _   \n",
       "1039    1         ZoPeachy  Zobella Thee Alpha __ê_____´Ù__ ...   \n",
       "1040    0        zzzakari4                                   _«_«ê_«__«ê   \n",
       "\n",
       "     lang                                        description  \\\n",
       "0      en                             _____Û___È_Ü´Ù   \n",
       "1      en                              BLACK. LIVES. MATTER.   \n",
       "2      en  Culver-Stockton College '20 ¢ Ô_Ô_Ô KM 1548...   \n",
       "3      en                                            #TXST22   \n",
       "4      en                                  WVU Nursing \n",
       "20   \n",
       "...   ...                                                ...   \n",
       "1036   en  22 Youtuber & Twitch Streamer trying to live t...   \n",
       "1037  und                                     |OUCÈ23__|   \n",
       "1038   no                                       Angelo state   \n",
       "1039   en  Harlot for hire. FinDom. 27. Nonbinary. they/t...   \n",
       "1040   en           i hate making bios oh my godddd UCIÈ21   \n",
       "\n",
       "                                                 tweets  \\\n",
       "0      .The owner of drip doesnt even have 100 mill,...   \n",
       "1     I haven’t talked to this girl since my sophomo...   \n",
       "2     ☝🏼👋🏼 ://t.co/7NcaO1fyc5 ://t.co/bkhrNcvp6Q  37...   \n",
       "3      yes but come to san marcos and live with me 🥰...   \n",
       "4      small :).Go get ready for dinner.   JACK are ...   \n",
       "...                                                 ...   \n",
       "1036  Goodnight my friends, much love.Drop a ❤️ if t...   \n",
       "1037  ROLL BOBBIES ROLL💚🖤💚🖤💚.We Are Texans! Im takin...   \n",
       "1038  one person followed me // automatically checke...   \n",
       "1039  Good morning! Say it back ♡  Friday! Send to p...   \n",
       "1040  i just know willows next album is gonna set me...   \n",
       "\n",
       "                                            img_path  \n",
       "0        labeled_users_1145/profile pics test/0.jpeg  \n",
       "1        labeled_users_1145/profile pics test/1.jpeg  \n",
       "2        labeled_users_1145/profile pics test/3.jpeg  \n",
       "3        labeled_users_1145/profile pics test/9.jpeg  \n",
       "4       labeled_users_1145/profile pics test/10.jpeg  \n",
       "...                                              ...  \n",
       "1036  labeled_users_1145/profile pics test/3266.jpeg  \n",
       "1037  labeled_users_1145/profile pics test/3268.jpeg  \n",
       "1038  labeled_users_1145/profile pics test/3272.jpeg  \n",
       "1039  labeled_users_1145/profile pics test/3274.jpeg  \n",
       "1040  labeled_users_1145/profile pics test/3279.jpeg  \n",
       "\n",
       "[1041 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d474ca3-c6f9-44ca-94bf-01bb68500b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        .The owner of drip doesnt even have 100 mill,...\n",
       "1       I haven’t talked to this girl since my sophomo...\n",
       "2       ☝🏼👋🏼 ://t.co/7NcaO1fyc5 ://t.co/bkhrNcvp6Q  37...\n",
       "3        yes but come to san marcos and live with me 🥰...\n",
       "4        small :).Go get ready for dinner.   JACK are ...\n",
       "                              ...                        \n",
       "1036    Goodnight my friends, much love.Drop a ❤️ if t...\n",
       "1037    ROLL BOBBIES ROLL💚🖤💚🖤💚.We Are Texans! Im takin...\n",
       "1038    one person followed me // automatically checke...\n",
       "1039    Good morning! Say it back ♡  Friday! Send to p...\n",
       "1040    i just know willows next album is gonna set me...\n",
       "Name: tweets, Length: 1041, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4ff565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1036    0\n",
       "1037    0\n",
       "1038    0\n",
       "1039    1\n",
       "1040    0\n",
       "Name: age, Length: 1041, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad70758a-ba9b-49b9-8d38-269189638ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    729\n",
       "1    312\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9baaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataSet(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, label):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        return (self.input_ids[idx], self.attention_mask[idx], self.label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4bede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(text_list, labels, ratio=0.8):\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        text_list,                      \n",
    "        add_special_tokens = True,             \n",
    "        truncation=True,\n",
    "        padding = 'max_length',     \n",
    "        return_tensors = 'pt',\n",
    "        max_length = 128\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    labels = torch.Tensor(labels).long()\n",
    "    \n",
    "    dataset = TextDataSet(input_ids, attention_mask, labels)\n",
    "    train_size = int(len(dataset)*ratio)\n",
    "    valid_size = len(dataset) - train_size\n",
    "    train_dataset, valid_dataset = random_split(dataset,[train_size,valid_size])\n",
    "    print('Train samples: {}  Valid samples: {}'.format(len(train_dataset),len(valid_dataset)))\n",
    "    \n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aaa4dbc-02de-4bba-b4e9-9afa4eff4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove emoji\n",
    "    tweet = re.sub(r'[\\U00010000-\\U0010ffff]', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d91fcd6-7767-4632-bb20-9c46ef956d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, train_loader, valid_loader, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.config = config\n",
    "\n",
    "        # take over whatever gpus are on the system\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.cuda.current_device()\n",
    "#             self.model = torch.nn.DataParallel(self.model).to(self.device)\n",
    "            self.model = self.model.to(self.device)\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        # DataParallel wrappers keep raw model object in .module attribute\n",
    "        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        os.makedirs(self.config.ckpt_path, exist_ok=True)\n",
    "        save_path = os.path.join(self.config.ckpt_path, self.config.model_name)\n",
    "        torch.save(raw_model.state_dict(), save_path)\n",
    "        logger.info(\"Save model to {}\".format(save_path))\n",
    "\n",
    "    def train(self):\n",
    "        model, config = self.model, self.config\n",
    "        raw_model = model.module if hasattr(self.model, \"module\") else model\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.learning_rate, betas=config.betas)\n",
    "        def run_epoch(split):\n",
    "            is_train = (split == 'train')\n",
    "            model.train(is_train)\n",
    "            loader = self.train_loader if is_train else self.valid_loader\n",
    "            \n",
    "            losses = []\n",
    "            all_y = []\n",
    "            all_y_pred = []\n",
    "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
    "            for it, (input_ids, attention_mask, y) in pbar:\n",
    "                # place data on the correct device\n",
    "#                 print(input_ids.shape,y.shape)\n",
    "                input_ids = input_ids.to(self.device)\n",
    "                attention_mask = attention_mask.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                # forward the model\n",
    "                with torch.set_grad_enabled(is_train):\n",
    "                    outputs = model(input_ids, attention_mask, labels=y)\n",
    "                    logits = outputs.logits\n",
    "                    loss = loss_fct(logits, y)\n",
    "                    loss = loss.mean() # collapse all losses if they are scattered on multiple gpus\n",
    "                    losses.append(loss.item())\n",
    "                    y_pred = torch.argmax(logits, dim=1)\n",
    "                    y = y.cpu().detach().numpy()\n",
    "                    y_pred = y_pred.cpu().detach().numpy()\n",
    "                    step_score = accuracy_score(y_pred, y)\n",
    "                    all_y.extend(y)\n",
    "                    all_y_pred.extend(y_pred)\n",
    "                \n",
    "                if is_train:\n",
    "\n",
    "                    # backprop and update the parameters\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # decay the learning rate based on our progress\n",
    "                    if config.lr_decay:\n",
    "                        self.tokens += batch_size # number of tokens processed this step (i.e. label is not -100)\n",
    "                        if self.tokens < config.warmup_tokens:\n",
    "                            # linear warmup\n",
    "                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens))\n",
    "                        else:\n",
    "                            # cosine learning rate decay\n",
    "                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
    "                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "                        lr = config.learning_rate * lr_mult\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group['lr'] = lr\n",
    "                    else:\n",
    "                        lr = config.learning_rate\n",
    "\n",
    "                    # report progress\n",
    "                    pbar.set_description(\"epoch {} iter {}: train loss {:.5f}, score {:.2f}%, lr {:e}\".format(epoch+1,it,loss.item(),step_score*100,lr))\n",
    "\n",
    "            if not is_train:\n",
    "                valid_loss = float(np.mean(losses))\n",
    "                all_y_pred = np.array(all_y_pred)\n",
    "                all_y = np.array(all_y)\n",
    "                valid_score = accuracy_score(all_y_pred, all_y)\n",
    "                logger.info(\"valid loss: %f\", valid_loss)\n",
    "                logger.info(\"valid score: %f\", valid_score)\n",
    "                print(classification_report(y_true=all_y, y_pred=all_y_pred))\n",
    "                return valid_loss\n",
    "\n",
    "        self.tokens = 0 # counter used for learning rate decay\n",
    "        best_loss = float('inf')\n",
    "        valid_loss = run_epoch('valid')\n",
    "        for epoch in range(config.max_epochs):\n",
    "            \n",
    "            run_epoch('train')\n",
    "            if self.valid_loader is not None:\n",
    "                valid_loss = run_epoch('valid')\n",
    "            # supports early stopping based on the valid loss, or just save always if no valid set is provided\n",
    "            good_model = self.valid_loader is None or valid_loss < best_loss\n",
    "            if self.config.ckpt_path is not None and good_model:\n",
    "                best_loss = valid_loss\n",
    "                self.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77c3bd03-d695-47ae-85d6-203cc7b73f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    max_epochs = 10\n",
    "    learning_rate = 1e-5\n",
    "    betas = (0.9, 0.95)\n",
    "    grad_norm_clip = 1.0\n",
    "    weight_decay = 0.1 # may useful optimize method\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    lr_decay = False # optimize method\n",
    "    warmup_tokens = 375e6 # use this to train model from a lower learning rate\n",
    "    final_tokens = 260e9 # all tokens during whole training process\n",
    "    # checkpoint settings\n",
    "    ckpt_path = './models_dir' # save model path\n",
    "    model_name = \"model_race.pt\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k,v in kwargs.items():\n",
    "            print(k,v)\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "369c1a7f-cbde-4dee-9468-89144e0ff3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a0410c-259d-48a7-affa-40b31d9cc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "for t, r in zip(df['tweets'].to_list(),df['age'].to_list()):\n",
    "    if r == 3:\n",
    "#         if random.random() < 0.125:\n",
    "        train_data.append(t)\n",
    "        train_label.append(r)\n",
    "    else:\n",
    "        train_data.append(t)\n",
    "        train_label.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b65370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 832  Valid samples: 209\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = encode_data(train_data,train_label)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ca7eb2b-5864-4848-84a3-44c9e2ba9c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification : all params: 109.483778M\n"
     ]
    }
   ],
   "source": [
    "loss_fct = nn.CrossEntropyLoss()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "# print model all parameters and parameters need training\n",
    "print('{} : all params: {:4f}M'.format(model._get_name(), sum(p.numel() for p in model.parameters()) / 1000 / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c43c258f-4bff-4fc5-8e9c-eb6cefebecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_epochs 10\n",
      "learning_rate 1e-05\n",
      "lr_decay True\n",
      "warmup_tokens 832\n",
      "final_tokens 8320\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "final_tokens = max_epochs * batch_size * len(train_loader)\n",
    "warmup_tokens = final_tokens//10\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, learning_rate=1e-5, lr_decay=True, \n",
    "                      warmup_tokens=warmup_tokens, final_tokens=final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe417d7d-5fe4-45ff-b758-b65ec9774ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2021 22:40:40 - valid loss: 0.703308\n",
      "12/07/2021 22:40:40 - valid score: 0.397129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.19      0.31       144\n",
      "           1       0.32      0.85      0.47        65\n",
      "\n",
      "    accuracy                           0.40       209\n",
      "   macro avg       0.53      0.52      0.39       209\n",
      "weighted avg       0.61      0.40      0.36       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 25: train loss 0.46862, score 81.25%, lr 1.000000e-05: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.49it/s]\n",
      "12/07/2021 22:40:48 - valid loss: 0.617577\n",
      "12/07/2021 22:40:48 - valid score: 0.688995\n",
      "/home/suyinpei1/anaconda3/envs/syp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/suyinpei1/anaconda3/envs/syp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/suyinpei1/anaconda3/envs/syp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82       144\n",
      "           1       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.69       209\n",
      "   macro avg       0.34      0.50      0.41       209\n",
      "weighted avg       0.47      0.69      0.56       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2021 22:40:52 - Save model to ./models_dir/model_race.pt\n",
      "epoch 2 iter 25: train loss 0.53344, score 78.12%, lr 9.698463e-06: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.68it/s]\n",
      "12/07/2021 22:40:59 - valid loss: 0.584370\n",
      "12/07/2021 22:40:59 - valid score: 0.688995\n",
      "/home/suyinpei1/anaconda3/envs/syp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/suyinpei1/anaconda3/envs/syp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/suyinpei1/anaconda3/envs/syp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82       144\n",
      "           1       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.69       209\n",
      "   macro avg       0.34      0.50      0.41       209\n",
      "weighted avg       0.47      0.69      0.56       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2021 22:41:03 - Save model to ./models_dir/model_race.pt\n",
      "epoch 3 iter 25: train loss 0.51128, score 81.25%, lr 8.830222e-06: 100%|████████████████████████████████| 26/26 [00:06<00:00,  3.72it/s]\n",
      "12/07/2021 22:41:11 - valid loss: 0.574160\n",
      "12/07/2021 22:41:11 - valid score: 0.684211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81       144\n",
      "           1       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.68       209\n",
      "   macro avg       0.34      0.50      0.41       209\n",
      "weighted avg       0.47      0.68      0.56       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2021 22:41:14 - Save model to ./models_dir/model_race.pt\n",
      "epoch 4 iter 25: train loss 0.59815, score 68.75%, lr 7.500000e-06: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.66it/s]\n",
      "12/07/2021 22:41:22 - valid loss: 0.582817\n",
      "12/07/2021 22:41:22 - valid score: 0.693780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.80       144\n",
      "           1       0.52      0.20      0.29        65\n",
      "\n",
      "    accuracy                           0.69       209\n",
      "   macro avg       0.62      0.56      0.55       209\n",
      "weighted avg       0.66      0.69      0.64       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 iter 25: train loss 0.44846, score 78.12%, lr 5.868241e-06: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.69it/s]\n",
      "12/07/2021 22:41:30 - valid loss: 0.586911\n",
      "12/07/2021 22:41:30 - valid score: 0.708134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80       144\n",
      "           1       0.55      0.37      0.44        65\n",
      "\n",
      "    accuracy                           0.71       209\n",
      "   macro avg       0.65      0.62      0.62       209\n",
      "weighted avg       0.69      0.71      0.69       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 iter 25: train loss 0.33576, score 87.50%, lr 4.131759e-06: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.69it/s]\n",
      "12/07/2021 22:41:37 - valid loss: 0.590936\n",
      "12/07/2021 22:41:37 - valid score: 0.708134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       144\n",
      "           1       0.54      0.40      0.46        65\n",
      "\n",
      "    accuracy                           0.71       209\n",
      "   macro avg       0.65      0.62      0.63       209\n",
      "weighted avg       0.69      0.71      0.69       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 iter 25: train loss 0.38200, score 87.50%, lr 2.500000e-06: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.69it/s]\n",
      "12/07/2021 22:41:45 - valid loss: 0.659406\n",
      "12/07/2021 22:41:45 - valid score: 0.693780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       144\n",
      "           1       0.51      0.37      0.43        65\n",
      "\n",
      "    accuracy                           0.69       209\n",
      "   macro avg       0.63      0.60      0.61       209\n",
      "weighted avg       0.67      0.69      0.68       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 iter 25: train loss 0.32676, score 87.50%, lr 1.169778e-06: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.71it/s]\n",
      "12/07/2021 22:41:52 - valid loss: 0.636753\n",
      "12/07/2021 22:41:52 - valid score: 0.679426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       144\n",
      "           1       0.48      0.48      0.48        65\n",
      "\n",
      "    accuracy                           0.68       209\n",
      "   macro avg       0.62      0.62      0.62       209\n",
      "weighted avg       0.68      0.68      0.68       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 iter 25: train loss 0.25552, score 96.88%, lr 1.000000e-06: 100%|████████████████████████████████| 26/26 [00:07<00:00,  3.71it/s]\n",
      "12/07/2021 22:42:00 - valid loss: 0.613113\n",
      "12/07/2021 22:42:00 - valid score: 0.688995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       144\n",
      "           1       0.50      0.40      0.44        65\n",
      "\n",
      "    accuracy                           0.69       209\n",
      "   macro avg       0.63      0.61      0.61       209\n",
      "weighted avg       0.67      0.69      0.68       209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 iter 25: train loss 0.32243, score 90.62%, lr 1.000000e-06: 100%|███████████████████████████████| 26/26 [00:07<00:00,  3.71it/s]\n",
      "12/07/2021 22:42:07 - valid loss: 0.640485\n",
      "12/07/2021 22:42:07 - valid score: 0.698565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       144\n",
      "           1       0.52      0.48      0.50        65\n",
      "\n",
      "    accuracy                           0.70       209\n",
      "   macro avg       0.64      0.64      0.64       209\n",
      "weighted avg       0.69      0.70      0.70       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, train_loader, valid_loader, tconf)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e5004-7530-4de1-8e85-a76d07c91b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
