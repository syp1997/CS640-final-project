{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS640 Final Project Computer Vision Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from keras.utils.np_utils import *\n",
    "#from keras import utils as np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalMaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_HEIGHT = 198\n",
    "IM_WIDTH = 198\n",
    "BATCH_SIZE = 4\n",
    "AGE_SAVE_DIR = \"age_model_checkpoint/\"\n",
    "RACE_SAVE_DIR = \"race_model_checkpoint/\"\n",
    "\n",
    "def delete_invalid_data(df):\n",
    "    length = len(df)\n",
    "    drop_list = []\n",
    "    for i in range(length):\n",
    "        r = df.iloc[i]\n",
    "        image_url = r['img_path']\n",
    "        try:\n",
    "            img = Image.open(image_url)\n",
    "        except IOError:\n",
    "            drop_list.append(i)\n",
    "    return df.drop(drop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051\n",
      "2976\n",
      "2381\n",
      "297\n",
      "298\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('clean_dataset.csv', usecols=[1, 2, 8])\n",
    "df['race'] = pd.to_numeric(df['race'])\n",
    "print(len(df))\n",
    "df = delete_invalid_data(df)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "train_dataset = df.sample(frac=0.8,ignore_index=True)\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "val_dataset = test_dataset.sample(frac=0.5)\n",
    "test_dataset = test_dataset.drop(val_dataset.index)\n",
    "val_dataset.reset_index(drop=True, inplace=True)\n",
    "test_dataset.reset_index(drop=True, inplace=True)\n",
    "print(len(df))\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_gen(df, for_training, picSize, batchSize):\n",
    "    races, ages, images = [], [], []\n",
    "    length = len(df)\n",
    "    while True:\n",
    "        for i in range(length):\n",
    "            r = df.iloc[i]\n",
    "            race, age, image = r['race'], r['age'], r['img_path']\n",
    "            img = Image.open(image)\n",
    "            img = img.resize(picSize, Image.BILINEAR)\n",
    "            img = img.convert('L')\n",
    "            img = np.array(img) / 255.0\n",
    "#             races.append(race - 1)\n",
    "            races.append(to_categorical((race - 1), 4))\n",
    "#             ages.append(age)\n",
    "#             ages.append(to_categorical(age, 2))\n",
    "            images.append(img)\n",
    "            if len(images) >= batchSize:\n",
    "                yield np.array(images), np.array(races)\n",
    "                images, races = [], []\n",
    "        if not for_training:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for testing\n",
    "picSize = (IM_WIDTH, IM_HEIGHT)\n",
    "validgen = race_gen(val_dataset, True, picSize, BATCH_SIZE)\n",
    "traingen = race_gen(train_dataset, True, picSize, BATCH_SIZE)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./race_model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "# next(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 198, 198, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 196, 196, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 194, 194, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 194, 194, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 97, 97, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 95, 95, 96)        55392     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 95, 95, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 47, 47, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 45, 45, 128)       110720    \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 45, 45, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 20, 20, 160)       184480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 20, 20, 160)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 10, 10, 160)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 8, 8, 192)         276672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_15 (Glo (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "race_output (Dense)          (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 673,860\n",
      "Trainable params: 672,580\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def conv_block(inp, filters=32, bn=True, pool=True):\n",
    "    _ = Conv2D(filters=filters, kernel_size=3, activation='relu')(inp)\n",
    "    if bn:\n",
    "        _ = BatchNormalization()(_)\n",
    "    if pool:\n",
    "        _ = MaxPool2D()(_)\n",
    "    return _\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(IM_HEIGHT, IM_WIDTH, 1))\n",
    "_ = conv_block(input_layer, filters=32, bn=False, pool=False)\n",
    "_ = conv_block(_, filters=32*2)\n",
    "_ = conv_block(_, filters=32*3)\n",
    "_ = conv_block(_, filters=32*4)\n",
    "_ = conv_block(_, filters=32*5)\n",
    "_ = conv_block(_, filters=32*6)\n",
    "bottleneck = GlobalMaxPool2D()(_)\n",
    "\n",
    "_ = Dense(units=128, activation='relu')(bottleneck)\n",
    "race_output = Dense(units=4, activation='softmax', name='race_output')(_)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=race_output)\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={ 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'race_output': 'accuracy'})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "595/595 [==============================] - 202s 338ms/step - loss: 1.1730 - accuracy: 0.7371 - val_loss: 1.1874 - val_accuracy: 0.7770\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 2/10\n",
      "595/595 [==============================] - 224s 377ms/step - loss: 0.8170 - accuracy: 0.7827 - val_loss: 1.0543 - val_accuracy: 0.7736\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 3/10\n",
      "595/595 [==============================] - 223s 375ms/step - loss: 0.8359 - accuracy: 0.7926 - val_loss: 0.9396 - val_accuracy: 0.7736\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 4/10\n",
      "595/595 [==============================] - 200s 336ms/step - loss: 0.7924 - accuracy: 0.8007 - val_loss: 0.9235 - val_accuracy: 0.7703\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 5/10\n",
      "595/595 [==============================] - 216s 363ms/step - loss: 0.8035 - accuracy: 0.7966 - val_loss: 0.9948 - val_accuracy: 0.7703\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 6/10\n",
      "595/595 [==============================] - 219s 368ms/step - loss: 0.8156 - accuracy: 0.8000 - val_loss: 0.9193 - val_accuracy: 0.7770\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 7/10\n",
      "595/595 [==============================] - 220s 371ms/step - loss: 0.8147 - accuracy: 0.7950 - val_loss: 0.9490 - val_accuracy: 0.7703\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 8/10\n",
      "595/595 [==============================] - 220s 370ms/step - loss: 0.8026 - accuracy: 0.7957 - val_loss: 0.8341 - val_accuracy: 0.7703\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 9/10\n",
      "595/595 [==============================] - 224s 376ms/step - loss: 0.8196 - accuracy: 0.7922 - val_loss: 0.9779 - val_accuracy: 0.7703\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n",
      "Epoch 10/10\n",
      "595/595 [==============================] - 206s 347ms/step - loss: 0.8147 - accuracy: 0.7932 - val_loss: 0.8826 - val_accuracy: 0.7703\n",
      "INFO:tensorflow:Assets written to: .\\race_model_checkpoint\\assets\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(traingen,\n",
    "                    steps_per_epoch=len(train_dataset)//batchSize,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validgen,\n",
    "                    validation_steps=len(val_dataset)//batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.8351134061813354, 'accuracy': 0.80859375}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testgen = race_gen(test_dataset, False, picSize, 128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(testgen, steps=len(test_dataset)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for race\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.81      1.00      0.90       104\n",
      "\n",
      "    accuracy                           0.81       128\n",
      "   macro avg       0.20      0.25      0.22       128\n",
      "weighted avg       0.66      0.81      0.73       128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "testgen = race_gen(test_dataset, False, picSize, 128)\n",
    "x_test, race_true= next(testgen)\n",
    "race_pred = model.predict_on_batch(x_test)\n",
    "race_true = race_true.argmax(axis=-1)\n",
    "race_pred = race_pred.argmax(axis=-1)\n",
    "print(\"Classification report for race\")\n",
    "print(classification_report(race_true, race_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# age prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041\n",
      "1039\n",
      "831\n",
      "104\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "df_age = pd.read_csv('clean_dataset_1145.csv', usecols=[0, 6])\n",
    "df_age['age'] = pd.to_numeric(df_age['age'])\n",
    "print(len(df_age))\n",
    "df_age = delete_invalid_data(df_age)\n",
    "df_age.reset_index(drop=True, inplace=True)\n",
    "train_dataset = df_age.sample(frac=0.8,ignore_index=True)\n",
    "test_dataset = df_age.drop(train_dataset.index)\n",
    "val_dataset = test_dataset.sample(frac=0.5)\n",
    "test_dataset = test_dataset.drop(val_dataset.index)\n",
    "val_dataset.reset_index(drop=True, inplace=True)\n",
    "test_dataset.reset_index(drop=True, inplace=True)\n",
    "print(len(df_age))\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_gen(df, for_training, picSize, batchSize):\n",
    "    ages, images = [], []\n",
    "    length = len(df)\n",
    "    while True:\n",
    "        for i in range(length):\n",
    "            r = df.iloc[i]\n",
    "            age, image = r['age'], r['img_path']\n",
    "            img = Image.open(image)\n",
    "            img = img.resize(picSize, Image.BILINEAR)\n",
    "            img = img.convert('L')\n",
    "            img = np.array(img) / 255.0\n",
    "#             ages.append(age)\n",
    "            ages.append(to_categorical(age, 2))\n",
    "            images.append(img)\n",
    "            if len(images) >= batchSize:\n",
    "                yield np.array(images), np.array(ages)\n",
    "                images, ages = [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "picSize = (IM_WIDTH, IM_HEIGHT)\n",
    "validgen = age_gen(val_dataset, True, picSize, BATCH_SIZE)\n",
    "traingen = age_gen(train_dataset, True, picSize, BATCH_SIZE)\n",
    "filepath = \"model_{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint('./age_model_checkpoint', monitor='val_loss')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 198, 198, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 196, 196, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 194, 194, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 194, 194, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 97, 97, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 95, 95, 96)        55392     \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 95, 95, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 47, 47, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 45, 45, 128)       110720    \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 45, 45, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 20, 20, 160)       184480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 20, 20, 160)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 10, 10, 160)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 8, 8, 192)         276672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_16 (Glo (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 673,602\n",
      "Trainable params: 672,322\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(IM_HEIGHT, IM_WIDTH, 1))\n",
    "_ = conv_block(input_layer, filters=32, bn=False, pool=False)\n",
    "_ = conv_block(_, filters=32*2)\n",
    "_ = conv_block(_, filters=32*3)\n",
    "_ = conv_block(_, filters=32*4)\n",
    "_ = conv_block(_, filters=32*5)\n",
    "_ = conv_block(_, filters=32*6)\n",
    "bottleneck = GlobalMaxPool2D()(_)\n",
    "\n",
    "_ = Dense(units=128, activation='relu')(bottleneck)\n",
    "age_output = Dense(units=2, activation='softmax', name='age_output')(_)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=age_output)\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={ 'age_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'accuracy'})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "207/207 [==============================] - 73s 347ms/step - loss: 1.5015 - accuracy: 0.5992 - val_loss: 1.3617 - val_accuracy: 0.7019\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 72s 346ms/step - loss: 0.7284 - accuracy: 0.6201 - val_loss: 0.6888 - val_accuracy: 0.6635\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 74s 359ms/step - loss: 0.6567 - accuracy: 0.6833 - val_loss: 0.6948 - val_accuracy: 0.6923\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 73s 351ms/step - loss: 0.6621 - accuracy: 0.6799 - val_loss: 0.7025 - val_accuracy: 0.5288\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 5/10\n",
      "207/207 [==============================] - 72s 350ms/step - loss: 0.6478 - accuracy: 0.6961 - val_loss: 0.6745 - val_accuracy: 0.6923\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 6/10\n",
      "207/207 [==============================] - 71s 343ms/step - loss: 0.6416 - accuracy: 0.7049 - val_loss: 0.6117 - val_accuracy: 0.6827\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 7/10\n",
      "207/207 [==============================] - 76s 367ms/step - loss: 0.6153 - accuracy: 0.7015 - val_loss: 0.7882 - val_accuracy: 0.6923\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 8/10\n",
      "207/207 [==============================] - 74s 359ms/step - loss: 0.6249 - accuracy: 0.6974 - val_loss: 0.6234 - val_accuracy: 0.7019\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 9/10\n",
      "207/207 [==============================] - 73s 354ms/step - loss: 0.6375 - accuracy: 0.6905 - val_loss: 0.6433 - val_accuracy: 0.7019\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n",
      "Epoch 10/10\n",
      "207/207 [==============================] - 72s 347ms/step - loss: 0.6471 - accuracy: 0.6891 - val_loss: 0.7196 - val_accuracy: 0.6923\n",
      "INFO:tensorflow:Assets written to: .\\age_model_checkpoint\\assets\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(traingen,\n",
    "                    steps_per_epoch=len(train_dataset)//BATCH_SIZE,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=validgen,\n",
    "                    validation_steps=len(val_dataset)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.9023867249488831, 'accuracy': 0.625}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testgen = age_gen(test_dataset, False, picSize, 104)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(testgen, steps=len(test_dataset)//104)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for race\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76        64\n",
      "           1       0.67      0.05      0.09        40\n",
      "\n",
      "    accuracy                           0.62       104\n",
      "   macro avg       0.65      0.52      0.43       104\n",
      "weighted avg       0.64      0.62      0.51       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testgen = age_gen(test_dataset, False, picSize, 104)\n",
    "x_test, age_true= next(testgen)\n",
    "age_pred = model.predict_on_batch(x_test)\n",
    "age_true = age_true.argmax(axis=-1)\n",
    "age_pred = age_pred.argmax(axis=-1)\n",
    "print(\"Classification report for race\")\n",
    "print(classification_report(age_true, age_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    728\n",
       "1    311\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_age.age.value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccee5cc862501c1aad1cf19888c2a2eca4026b72d187db43d5e889cbdc6ee97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
